{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:34:31.114247Z",
     "iopub.status.busy": "2025-05-02T00:34:31.113488Z",
     "iopub.status.idle": "2025-05-02T00:34:32.286616Z",
     "shell.execute_reply": "2025-05-02T00:34:32.285345Z",
     "shell.execute_reply.started": "2025-05-02T00:34:31.114213Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import pyarrow\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:54:46.955318Z",
     "iopub.status.busy": "2025-05-01T23:54:46.954946Z",
     "iopub.status.idle": "2025-05-01T23:54:57.631388Z",
     "shell.execute_reply": "2025-05-01T23:54:57.630354Z",
     "shell.execute_reply.started": "2025-05-01T23:54:46.955294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Already loaded on kaggle\n",
    "calendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\n",
    "#train_val_o = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\n",
    "sell_prices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\n",
    "train_val_o = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\n",
    "\n",
    "\n",
    "# Taking sample to prevent kernel\n",
    "#np.random.seed(42)\n",
    "#sample_ids = np.random.choice(train_val_o['id'].unique(), size=1000, replace=False)\n",
    "#train_val = train_val_o[train_val_o['id'].isin(sample_ids)]\n",
    "train_val = train_val_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:54:57.633932Z",
     "iopub.status.busy": "2025-05-01T23:54:57.633647Z",
     "iopub.status.idle": "2025-05-01T23:54:58.669917Z",
     "shell.execute_reply": "2025-05-01T23:54:58.668974Z",
     "shell.execute_reply.started": "2025-05-01T23:54:57.633910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Missing values in calendar --\n",
      "date               0\n",
      "wm_yr_wk           0\n",
      "weekday            0\n",
      "wday               0\n",
      "month              0\n",
      "year               0\n",
      "d                  0\n",
      "event_name_1    1807\n",
      "event_type_1    1807\n",
      "event_name_2    1964\n",
      "event_type_2    1964\n",
      "snap_CA            0\n",
      "snap_TX            0\n",
      "snap_WI            0\n",
      "dtype: int64\n",
      "\n",
      "-- Data types (info) --\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          1969 non-null   object\n",
      " 1   wm_yr_wk      1969 non-null   int64 \n",
      " 2   weekday       1969 non-null   object\n",
      " 3   wday          1969 non-null   int64 \n",
      " 4   month         1969 non-null   int64 \n",
      " 5   year          1969 non-null   int64 \n",
      " 6   d             1969 non-null   object\n",
      " 7   event_name_1  162 non-null    object\n",
      " 8   event_type_1  162 non-null    object\n",
      " 9   event_name_2  5 non-null      object\n",
      " 10  event_type_2  5 non-null      object\n",
      " 11  snap_CA       1969 non-null   int64 \n",
      " 12  snap_TX       1969 non-null   int64 \n",
      " 13  snap_WI       1969 non-null   int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 215.5+ KB\n",
      "\n",
      "-- Descriptive statistics --\n",
      "              date      wm_yr_wk   weekday         wday        month  \\\n",
      "count         1969   1969.000000      1969  1969.000000  1969.000000   \n",
      "unique        1969           NaN         7          NaN          NaN   \n",
      "top     2011-01-29           NaN  Saturday          NaN          NaN   \n",
      "freq             1           NaN       282          NaN          NaN   \n",
      "mean           NaN  11347.086338       NaN     3.997461     6.325546   \n",
      "std            NaN    155.277043       NaN     2.001141     3.416864   \n",
      "min            NaN  11101.000000       NaN     1.000000     1.000000   \n",
      "25%            NaN  11219.000000       NaN     2.000000     3.000000   \n",
      "50%            NaN  11337.000000       NaN     4.000000     6.000000   \n",
      "75%            NaN  11502.000000       NaN     6.000000     9.000000   \n",
      "max            NaN  11621.000000       NaN     7.000000    12.000000   \n",
      "\n",
      "               year     d event_name_1 event_type_1  event_name_2  \\\n",
      "count   1969.000000  1969          162          162             5   \n",
      "unique          NaN  1969           30            4             4   \n",
      "top             NaN   d_1    SuperBowl    Religious  Father's day   \n",
      "freq            NaN     1            6           55             2   \n",
      "mean    2013.288471   NaN          NaN          NaN           NaN   \n",
      "std        1.580198   NaN          NaN          NaN           NaN   \n",
      "min     2011.000000   NaN          NaN          NaN           NaN   \n",
      "25%     2012.000000   NaN          NaN          NaN           NaN   \n",
      "50%     2013.000000   NaN          NaN          NaN           NaN   \n",
      "75%     2015.000000   NaN          NaN          NaN           NaN   \n",
      "max     2016.000000   NaN          NaN          NaN           NaN   \n",
      "\n",
      "       event_type_2      snap_CA      snap_TX      snap_WI  \n",
      "count             5  1969.000000  1969.000000  1969.000000  \n",
      "unique            2          NaN          NaN          NaN  \n",
      "top        Cultural          NaN          NaN          NaN  \n",
      "freq              4          NaN          NaN          NaN  \n",
      "mean            NaN     0.330117     0.330117     0.330117  \n",
      "std             NaN     0.470374     0.470374     0.470374  \n",
      "min             NaN     0.000000     0.000000     0.000000  \n",
      "25%             NaN     0.000000     0.000000     0.000000  \n",
      "50%             NaN     0.000000     0.000000     0.000000  \n",
      "75%             NaN     1.000000     1.000000     1.000000  \n",
      "max             NaN     1.000000     1.000000     1.000000  \n",
      "-- Missing values in sell_prices --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_id      0\n",
      "item_id       0\n",
      "wm_yr_wk      0\n",
      "sell_price    0\n",
      "dtype: int64\n",
      "\n",
      "-- Data types (info) --\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6841121 entries, 0 to 6841120\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   store_id    object \n",
      " 1   item_id     object \n",
      " 2   wm_yr_wk    int64  \n",
      " 3   sell_price  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 208.8+ MB\n",
      "\n",
      "-- Descriptive stats for sell_price --\n",
      "count    6.841121e+06\n",
      "mean     4.410952e+00\n",
      "std      3.408814e+00\n",
      "min      1.000000e-02\n",
      "25%      2.180000e+00\n",
      "50%      3.470000e+00\n",
      "75%      5.840000e+00\n",
      "max      1.073200e+02\n",
      "Name: sell_price, dtype: float64\n",
      "Unique item IDs: 3049\n",
      "Unique store IDs: 10\n",
      "Unique dept IDs: 7\n",
      "Unique cat IDs: 3\n",
      "Unique state IDs: 3\n"
     ]
    }
   ],
   "source": [
    "# EDA steps\n",
    "print(\"-- Missing values in calendar --\")\n",
    "print(calendar.isnull().sum())\n",
    "\n",
    "print(\"\\n-- Data types (info) --\")\n",
    "calendar.info()\n",
    "\n",
    "print(\"\\n-- Descriptive statistics --\")\n",
    "print(calendar.describe(include='all'))\n",
    "\n",
    "print(\"-- Missing values in sell_prices --\")\n",
    "print(sell_prices.isnull().sum())\n",
    "\n",
    "print(\"\\n-- Data types (info) --\")\n",
    "sell_prices.info()\n",
    "\n",
    "print(\"\\n-- Descriptive stats for sell_price --\")\n",
    "print(sell_prices[\"sell_price\"].describe())\n",
    "\n",
    "print(\"Unique item IDs:\", train_val[\"item_id\"].nunique())\n",
    "print(\"Unique store IDs:\", train_val[\"store_id\"].nunique())\n",
    "print(\"Unique dept IDs:\", train_val[\"dept_id\"].nunique())\n",
    "print(\"Unique cat IDs:\", train_val[\"cat_id\"].nunique())\n",
    "print(\"Unique state IDs:\", train_val[\"state_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:54:58.671134Z",
     "iopub.status.busy": "2025-05-01T23:54:58.670833Z",
     "iopub.status.idle": "2025-05-01T23:55:59.567180Z",
     "shell.execute_reply": "2025-05-01T23:55:59.566275Z",
     "shell.execute_reply.started": "2025-05-01T23:54:58.671111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_val after melt: (59181090, 8)\n",
      "Shape after merged with calendar data: (59181090, 21)\n"
     ]
    }
   ],
   "source": [
    "# Melt the train_val to merge with other datasets\n",
    "sales_eval = pd.melt(train_val, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\n",
    "print(\"Shape of train_val after melt:\", sales_eval.shape)\n",
    "\n",
    "# Merge with calendar data\n",
    "df = pd.merge(sales_eval, calendar, on='d', how='left')\n",
    "print(\"Shape after merged with calendar data:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:55:59.568376Z",
     "iopub.status.busy": "2025-05-01T23:55:59.568075Z",
     "iopub.status.idle": "2025-05-01T23:57:48.896059Z",
     "shell.execute_reply": "2025-05-01T23:57:48.895035Z",
     "shell.execute_reply.started": "2025-05-01T23:55:59.568347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 21)\n",
      "After memory reduction:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            category      \n",
      " 1   item_id       category      \n",
      " 2   dept_id       category      \n",
      " 3   cat_id        category      \n",
      " 4   store_id      category      \n",
      " 5   state_id      category      \n",
      " 6   d             category      \n",
      " 7   sold          int16         \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       category      \n",
      " 11  wday          int8          \n",
      " 12  month         int8          \n",
      " 13  year          int16         \n",
      " 14  event_name_1  category      \n",
      " 15  event_type_1  category      \n",
      " 16  event_name_2  category      \n",
      " 17  event_type_2  category      \n",
      " 18  snap_CA       int8          \n",
      " 19  snap_TX       int8          \n",
      " 20  snap_WI       int8          \n",
      "dtypes: category(12), datetime64[ns](1), int16(3), int8(5)\n",
      "memory usage: 1.9 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Downcast the data for easy and fast processing\n",
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "\n",
    "    for i, t in enumerate(types):\n",
    "        col = cols[i]\n",
    "\n",
    "        if 'int' in str(t):\n",
    "            if df[col].min() > np.iinfo(np.int8).min and df[col].max() < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif df[col].min() > np.iinfo(np.int16).min and df[col].max() < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif df[col].min() > np.iinfo(np.int32).min and df[col].max() < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        elif 'float' in str(t):\n",
    "            if df[col].min() > np.finfo(np.float16).min and df[col].max() < np.finfo(np.float16).max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif df[col].min() > np.finfo(np.float32).min and df[col].max() < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        elif t == object:\n",
    "            if col == 'date':\n",
    "                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = downcast(df)\n",
    "\n",
    "# Convert date column back to datetime\n",
    "df['date'] = df['date'].astype(str)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(df.shape)\n",
    "print('After memory reduction:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:57:48.897293Z",
     "iopub.status.busy": "2025-05-01T23:57:48.896985Z",
     "iopub.status.idle": "2025-05-01T23:58:22.679779Z",
     "shell.execute_reply": "2025-05-01T23:58:22.678995Z",
     "shell.execute_reply.started": "2025-05-01T23:57:48.897262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after merged with price data: (59181090, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sold</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sold       date  wm_yr_wk   weekday  wday  month  year  \\\n",
       "0       CA  d_1     0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "1       CA  d_1     0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "2       CA  d_1     0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "3       CA  d_1     0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "4       CA  d_1     0 2011-01-29     11101  Saturday     1      1  2011   \n",
       "\n",
       "  event_name_1 event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  \\\n",
       "0          NaN          NaN          NaN          NaN        0        0   \n",
       "1          NaN          NaN          NaN          NaN        0        0   \n",
       "2          NaN          NaN          NaN          NaN        0        0   \n",
       "3          NaN          NaN          NaN          NaN        0        0   \n",
       "4          NaN          NaN          NaN          NaN        0        0   \n",
       "\n",
       "   snap_WI  sell_price  \n",
       "0        0         NaN  \n",
       "1        0         NaN  \n",
       "2        0         NaN  \n",
       "3        0         NaN  \n",
       "4        0         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with price data\n",
    "df = pd.merge(df, sell_prices, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "print(\"Shape after merged with price data:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:59:22.319616Z",
     "iopub.status.busy": "2025-05-01T23:59:22.319290Z",
     "iopub.status.idle": "2025-05-01T23:59:22.443304Z",
     "shell.execute_reply": "2025-05-01T23:59:22.442383Z",
     "shell.execute_reply.started": "2025-05-01T23:59:22.319589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del calendar, train_val_o, sell_prices, train_val  # example\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T23:59:24.834577Z",
     "iopub.status.busy": "2025-05-01T23:59:24.834291Z",
     "iopub.status.idle": "2025-05-02T00:00:05.243652Z",
     "shell.execute_reply": "2025-05-02T00:00:05.242186Z",
     "shell.execute_reply.started": "2025-05-01T23:59:24.834555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/310429233.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for _, sub_df in df.groupby('store_id'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 31)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for _, sub_df in df.groupby('store_id'):\n",
    "    sub_df = sub_df.sort_values('date').copy()\n",
    "    \n",
    "    sub_df['weekofyear'] = sub_df['date'].dt.isocalendar().week\n",
    "    sub_df['dayofmonth'] = sub_df['date'].dt.day\n",
    "    sub_df['day_of_year'] = sub_df['date'].dt.dayofyear\n",
    "    sub_df['weekend'] = sub_df['date'].dt.weekday.isin([5, 6]).astype(np.uint8)\n",
    "    sub_df['is_month_start'] = sub_df['date'].dt.is_month_start.astype(np.uint8)\n",
    "    sub_df['is_month_end'] = sub_df['date'].dt.is_month_end.astype(np.uint8)\n",
    "    sub_df['is_quarter_start'] = sub_df['date'].dt.is_quarter_start.astype(np.uint8)\n",
    "    sub_df['is_quarter_end'] = sub_df['date'].dt.is_quarter_end.astype(np.uint8)\n",
    "    sub_df['is_event'] = sub_df['event_name_1'].notnull().astype(np.uint8)\n",
    "    sub_df['wday'] = sub_df['date'].dt.weekday + 1\n",
    "\n",
    "    dfs.append(sub_df)\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True)\n",
    "del dfs, sub_df\n",
    "gc.collect()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:00:05.245615Z",
     "iopub.status.busy": "2025-05-02T00:00:05.245252Z",
     "iopub.status.idle": "2025-05-02T00:00:40.891090Z",
     "shell.execute_reply": "2025-05-02T00:00:40.889776Z",
     "shell.execute_reply.started": "2025-05-02T00:00:05.245590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 33)\n"
     ]
    }
   ],
   "source": [
    "# Event/Holiday Features\n",
    "\n",
    "# Step 1: Ensure datetime and sorting\n",
    "df = df.sort_values('date')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Step 2: Create event DataFrame\n",
    "events = df[df['event_name_1'].notnull()][['date']].copy()\n",
    "events = events.sort_values('date')\n",
    "events = events.rename(columns={'date': 'event_date'})\n",
    "\n",
    "# Step 3: Use merge_asof for previous and next events\n",
    "df = pd.merge_asof(df, events, left_on='date', right_on='event_date', direction='backward')\n",
    "df['days_since_event'] = (df['date'] - df['event_date']).dt.days\n",
    "\n",
    "df = pd.merge_asof(df, events, left_on='date', right_on='event_date', direction='forward', suffixes=('', '_next'))\n",
    "df['days_until_event'] = (df['event_date_next'] - df['date']).dt.days\n",
    "\n",
    "# Data Cleanup\n",
    "df.drop(columns=['event_date', 'event_date_next'], inplace=True)\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:00:40.893436Z",
     "iopub.status.busy": "2025-05-02T00:00:40.892963Z",
     "iopub.status.idle": "2025-05-02T00:01:34.298848Z",
     "shell.execute_reply": "2025-05-02T00:01:34.297984Z",
     "shell.execute_reply.started": "2025-05-02T00:00:40.893392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2266465746.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['price_max'] = df.groupby('item_id')['sell_price'].transform('max')\n",
      "/tmp/ipykernel_31/2266465746.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['price_min'] = df.groupby('item_id')['sell_price'].transform('min')\n",
      "/tmp/ipykernel_31/2266465746.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['price_std'] = df.groupby('item_id')['sell_price'].transform('std')\n",
      "/tmp/ipykernel_31/2266465746.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['prev_price'] = df.groupby('item_id')['sell_price'].shift(1)\n",
      "/tmp/ipykernel_31/2266465746.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['prev_month_price'] = df.groupby('item_id')['sell_price'].shift(28)  # assuming daily data & 28-day months\n",
      "/tmp/ipykernel_31/2266465746.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['price_avg'] = df.groupby('item_id')['sell_price'].transform('mean')\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 40)\n"
     ]
    }
   ],
   "source": [
    "# Price Features\n",
    "\n",
    "df['price_max'] = df.groupby('item_id')['sell_price'].transform('max')\n",
    "df['price_min'] = df.groupby('item_id')['sell_price'].transform('min')\n",
    "df['price_std'] = df.groupby('item_id')['sell_price'].transform('std')\n",
    "df['price_norm'] = df['sell_price'] / df['price_max']\n",
    "df = df.sort_values(['item_id', 'date'])\n",
    "df['prev_price'] = df.groupby('item_id')['sell_price'].shift(1)\n",
    "df['price_momentum'] = df['sell_price'] / df['prev_price']\n",
    "df['prev_month_price'] = df.groupby('item_id')['sell_price'].shift(28)  # assuming daily data & 28-day months\n",
    "df['price_change_from_last_month'] = (df['sell_price'] - df['prev_month_price']).fillna(0)\n",
    "df['price_avg'] = df.groupby('item_id')['sell_price'].transform('mean')\n",
    "df['discount_flag'] = (df['sell_price'] < df['price_avg']).astype(int)\n",
    "df.drop(columns=['prev_price', 'prev_month_price', 'price_avg'], inplace=True)\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:01:34.300195Z",
     "iopub.status.busy": "2025-05-02T00:01:34.299941Z",
     "iopub.status.idle": "2025-05-02T00:02:52.244129Z",
     "shell.execute_reply": "2025-05-02T00:02:52.242989Z",
     "shell.execute_reply.started": "2025-05-02T00:01:34.300176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/676198016.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['last_snap_date'] = df.groupby('store_id')['snap_date'].ffill()\n",
      "/tmp/ipykernel_31/676198016.py:28: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['cumulative_snap_days'] = df.groupby('store_id')['snap_active'].cumsum()\n",
      "/tmp/ipykernel_31/676198016.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby('store_id')['snap_date_future']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 43)\n"
     ]
    }
   ],
   "source": [
    "# Promotion/SNAP Features\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Vectorized SNAP flag creation\n",
    "conditions = [\n",
    "    df['store_id'].str.startswith('CA'),\n",
    "    df['store_id'].str.startswith('TX'),\n",
    "    df['store_id'].str.startswith('WI')\n",
    "]\n",
    "choices = [df['snap_CA'], df['snap_TX'], df['snap_WI']]\n",
    "df['snap_active'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "# Sort values\n",
    "df = df.sort_values(['store_id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Create helper: last SNAP active date using forward fill logic\n",
    "df['snap_date'] = df['date'].where(df['snap_active'] == 1)\n",
    "\n",
    "# Forward fill within store groups\n",
    "df['last_snap_date'] = df.groupby('store_id')['snap_date'].ffill()\n",
    "\n",
    "# Compute days since last SNAP active\n",
    "df['days_since_snap'] = (df['date'] - df['last_snap_date']).dt.days\n",
    "df.loc[df['snap_active'] == 1, 'days_since_snap'] = 0\n",
    "\n",
    "df['cumulative_snap_days'] = df.groupby('store_id')['snap_active'].cumsum()\n",
    "\n",
    "# Create 'snap_date_future' column where SNAP is active\n",
    "df['snap_date_future'] = df['date'].where(df['snap_active'] == 1)\n",
    "\n",
    "# Reverse the DataFrame within each group to apply forward-fill \"backwards\"\n",
    "df['snap_date_future'] = (\n",
    "    df.iloc[::-1]\n",
    "    .groupby('store_id')['snap_date_future']\n",
    "    .ffill()\n",
    "    .iloc[::-1]\n",
    ")\n",
    "\n",
    "# Calculate days until next SNAP date\n",
    "df['days_until_next_snap'] = (df['snap_date_future'] - df['date']).dt.days\n",
    "df.loc[df['snap_active'] == 1, 'days_until_next_snap'] = 0\n",
    "\n",
    "# Cleanup\n",
    "df.drop(columns=['snap_date_future','snap_date','last_snap_date','cumulative_snap_days'], inplace=True)\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:02:52.245776Z",
     "iopub.status.busy": "2025-05-02T00:02:52.245386Z",
     "iopub.status.idle": "2025-05-02T00:03:06.347340Z",
     "shell.execute_reply": "2025-05-02T00:03:06.346292Z",
     "shell.execute_reply.started": "2025-05-02T00:02:52.245744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2648118170.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby('id')['sold'].shift(lag)\n",
      "/tmp/ipykernel_31/2648118170.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby('id')['sold'].shift(lag)\n",
      "/tmp/ipykernel_31/2648118170.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby('id')['sold'].shift(lag)\n",
      "/tmp/ipykernel_31/2648118170.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'sales_lag_{lag}'] = df.groupby('id')['sold'].shift(lag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 47)\n"
     ]
    }
   ],
   "source": [
    "#Lag features\n",
    "lags = [1, 7, 14, 28]\n",
    "\n",
    "for lag in lags:\n",
    "    df[f'sales_lag_{lag}'] = df.groupby('id')['sold'].shift(lag)\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:03:06.349245Z",
     "iopub.status.busy": "2025-05-02T00:03:06.348808Z",
     "iopub.status.idle": "2025-05-02T00:04:16.679616Z",
     "shell.execute_reply": "2025-05-02T00:04:16.678565Z",
     "shell.execute_reply.started": "2025-05-02T00:03:06.349213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 47)\n",
      "After memory reduction:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 47 columns):\n",
      " #   Column                        Dtype         \n",
      "---  ------                        -----         \n",
      " 0   id                            category      \n",
      " 1   item_id                       category      \n",
      " 2   dept_id                       category      \n",
      " 3   cat_id                        category      \n",
      " 4   store_id                      category      \n",
      " 5   state_id                      category      \n",
      " 6   d                             category      \n",
      " 7   sold                          int16         \n",
      " 8   date                          datetime64[ns]\n",
      " 9   wm_yr_wk                      int16         \n",
      " 10  weekday                       category      \n",
      " 11  wday                          int8          \n",
      " 12  month                         int8          \n",
      " 13  year                          int16         \n",
      " 14  event_name_1                  category      \n",
      " 15  event_type_1                  category      \n",
      " 16  event_name_2                  category      \n",
      " 17  event_type_2                  category      \n",
      " 18  snap_CA                       int8          \n",
      " 19  snap_TX                       int8          \n",
      " 20  snap_WI                       int8          \n",
      " 21  sell_price                    float16       \n",
      " 22  weekofyear                    UInt32        \n",
      " 23  dayofmonth                    int8          \n",
      " 24  day_of_year                   int16         \n",
      " 25  weekend                       int8          \n",
      " 26  is_month_start                int8          \n",
      " 27  is_month_end                  int8          \n",
      " 28  is_quarter_start              int8          \n",
      " 29  is_quarter_end                int8          \n",
      " 30  is_event                      int8          \n",
      " 31  days_since_event              float16       \n",
      " 32  days_until_event              float16       \n",
      " 33  price_max                     float16       \n",
      " 34  price_min                     float16       \n",
      " 35  price_std                     float16       \n",
      " 36  price_norm                    float16       \n",
      " 37  price_momentum                float16       \n",
      " 38  price_change_from_last_month  float16       \n",
      " 39  discount_flag                 int8          \n",
      " 40  snap_active                   int8          \n",
      " 41  days_since_snap               float16       \n",
      " 42  days_until_next_snap          float16       \n",
      " 43  sales_lag_1                   float16       \n",
      " 44  sales_lag_7                   float16       \n",
      " 45  sales_lag_14                  float16       \n",
      " 46  sales_lag_28                  float16       \n",
      "dtypes: UInt32(1), category(12), datetime64[ns](1), float16(15), int16(4), int8(14)\n",
      "memory usage: 4.4 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Downcast the data for easy and fast processing\n",
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "\n",
    "    for i, t in enumerate(types):\n",
    "        col = cols[i]\n",
    "\n",
    "        if 'int' in str(t):\n",
    "            if df[col].min() > np.iinfo(np.int8).min and df[col].max() < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif df[col].min() > np.iinfo(np.int16).min and df[col].max() < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif df[col].min() > np.iinfo(np.int32).min and df[col].max() < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        elif 'float' in str(t):\n",
    "            if df[col].min() > np.finfo(np.float16).min and df[col].max() < np.finfo(np.float16).max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif df[col].min() > np.finfo(np.float32).min and df[col].max() < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        elif t == object:\n",
    "            if col == 'date':\n",
    "                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = downcast(df)\n",
    "\n",
    "# Convert date column back to datetime\n",
    "df['date'] = df['date'].astype(str)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.to_feather('/kaggle/working/df.feather')\n",
    "\n",
    "print(df.shape)\n",
    "print('After memory reduction:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:04:16.681239Z",
     "iopub.status.busy": "2025-05-02T00:04:16.680879Z",
     "iopub.status.idle": "2025-05-02T00:04:16.686994Z",
     "shell.execute_reply": "2025-05-02T00:04:16.686020Z",
     "shell.execute_reply.started": "2025-05-02T00:04:16.681205Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/kaggle/working/rolling_chunks\"\n",
    "\n",
    "# Find all files in the folder\n",
    "files = glob.glob(os.path.join(folder_path, \"*\"))\n",
    "\n",
    "# Remove each file\n",
    "for file in files:\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:04:16.688540Z",
     "iopub.status.busy": "2025-05-02T00:04:16.688250Z",
     "iopub.status.idle": "2025-05-02T00:13:01.713607Z",
     "shell.execute_reply": "2025-05-02T00:13:01.712753Z",
     "shell.execute_reply.started": "2025-05-02T00:04:16.688495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:17: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:18: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:19: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
      "/tmp/ipykernel_31/2789390266.py:23: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Rolling Window Features\n",
    "\n",
    "# Ensure data is sorted correctly\n",
    "df = df.sort_values(['id', 'date']).copy()\n",
    "output_path = '/kaggle/working/rolling_chunks'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "id_list = df['id'].unique()\n",
    "batch_size = 4000\n",
    "\n",
    "for i in range(0, len(id_list), batch_size):\n",
    "    batch_ids = id_list[i:i+batch_size]\n",
    "    chunk = df[df['id'].isin(batch_ids)].copy()\n",
    "    chunk = chunk.sort_values(['id', 'date'])\n",
    "\n",
    "    # Safe rolling and expanding using groupby().transform()\n",
    "    chunk['rolling_mean_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).mean()).astype(np.float32)\n",
    "    chunk['rolling_std_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).std()).astype(np.float32)\n",
    "    chunk['rolling_mean_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).mean()).astype(np.float32)\n",
    "    chunk['rolling_std_14'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(14).std()).astype(np.float32)\n",
    "    chunk['expanding_mean'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).expanding().mean()).astype(np.float32)\n",
    "    chunk['rolling_min_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).min()).astype(np.float32)\n",
    "    chunk['rolling_max_7'] = chunk.groupby('id')['sold'].transform(lambda x: x.shift(1).rolling(7).max()).astype(np.float32)\n",
    "\n",
    "    # Save batch to disk\n",
    "    chunk.to_feather(f\"{output_path}/rolling_batch_{i}.feather\")\n",
    "    del chunk\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:24:53.213398Z",
     "iopub.status.busy": "2025-05-02T00:24:53.212540Z",
     "iopub.status.idle": "2025-05-02T00:26:58.989840Z",
     "shell.execute_reply": "2025-05-02T00:26:58.988730Z",
     "shell.execute_reply.started": "2025-05-02T00:24:53.213366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading /kaggle/working/rolling_chunks/rolling_batch_0.feather (1/8)\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_12000.feather (2/8)\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_16000.feather (3/8)\n",
      " Written batch ending with file 3\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_20000.feather (4/8)\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_24000.feather (5/8)\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_28000.feather (6/8)\n",
      " Written batch ending with file 6\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_4000.feather (7/8)\n",
      " Reading /kaggle/working/rolling_chunks/rolling_batch_8000.feather (8/8)\n",
      " Written batch ending with file 8\n",
      " All data written to: /kaggle/working/df_rolling.parquet\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "input_folder = '/kaggle/working/rolling_chunks'\n",
    "feather_files = sorted(glob.glob(f\"{input_folder}/*.feather\"))\n",
    "output_file = '/kaggle/working/df_rolling.parquet'\n",
    "\n",
    "batch_size = 3\n",
    "buffer = []\n",
    "writer = None\n",
    "\n",
    "for i, file in enumerate(feather_files):\n",
    "    print(f\" Reading {file} ({i+1}/{len(feather_files)})\")\n",
    "    chunk = pd.read_feather(file)\n",
    "    buffer.append(chunk)\n",
    "\n",
    "    if len(buffer) == batch_size or i == len(feather_files) - 1:\n",
    "        df_out = pd.concat(buffer, ignore_index=True)\n",
    "        table = pa.Table.from_pandas(df_out)\n",
    "\n",
    "        # Initialize writer on first write\n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(output_file, table.schema, compression='snappy')\n",
    "\n",
    "        writer.write_table(table)\n",
    "        print(f\" Written batch ending with file {i+1}\")\n",
    "\n",
    "        buffer.clear()\n",
    "\n",
    "# Close the writer properly\n",
    "if writer is not None:\n",
    "    writer.close()\n",
    "    print(f\" All data written to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:29:13.375453Z",
     "iopub.status.busy": "2025-05-02T00:29:13.374904Z",
     "iopub.status.idle": "2025-05-02T00:29:39.801968Z",
     "shell.execute_reply": "2025-05-02T00:29:39.800895Z",
     "shell.execute_reply.started": "2025-05-02T00:29:13.375418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 54)\n"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file\n",
    "df = pd.read_parquet('/kaggle/working/df_rolling.parquet')\n",
    "\n",
    "# Save as Feather\n",
    "df.to_feather('/kaggle/working/df_rolling.feather')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:29:39.803902Z",
     "iopub.status.busy": "2025-05-02T00:29:39.803536Z",
     "iopub.status.idle": "2025-05-02T00:29:50.485843Z",
     "shell.execute_reply": "2025-05-02T00:29:50.484851Z",
     "shell.execute_reply.started": "2025-05-02T00:29:39.803866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 57)\n"
     ]
    }
   ],
   "source": [
    "# Interaction features\n",
    "\n",
    "df['snap_event'] = df['snap_active'] * df['is_event'].notna().astype(int)\n",
    "df['price_event'] = df['discount_flag'] * df['is_event'].notna().astype(int)\n",
    "df['weekend_event'] = df['weekend'] * df['is_event'].notna().astype(int)\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:29:50.487185Z",
     "iopub.status.busy": "2025-05-02T00:29:50.486915Z",
     "iopub.status.idle": "2025-05-02T00:30:55.700297Z",
     "shell.execute_reply": "2025-05-02T00:30:55.699298Z",
     "shell.execute_reply.started": "2025-05-02T00:29:50.487162Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/2883972013.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['cumulative_sales'] = df.groupby('id')['sold'].cumsum()\n",
      "/tmp/ipykernel_212/2883972013.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['cumulative_mean_sales'] = df.groupby('id')['sold'].transform(lambda x: x.expanding().mean())\n",
      "/tmp/ipykernel_212/2883972013.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['days_since_last_sale'] = df.groupby('id')['sold'].transform(days_since_last_sale)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 60)\n"
     ]
    }
   ],
   "source": [
    "# Cumulative/Expanding Features\n",
    "\n",
    "df['cumulative_sales'] = df.groupby('id')['sold'].cumsum()\n",
    "df['cumulative_mean_sales'] = df.groupby('id')['sold'].transform(lambda x: x.expanding().mean())\n",
    "\n",
    "def days_since_last_sale(x):\n",
    "    out = []\n",
    "    last_day = -1\n",
    "    for i, val in enumerate(x):\n",
    "        if val > 0:\n",
    "            last_day = i\n",
    "        out.append(i - last_day if last_day != -1 else np.nan)\n",
    "    return out\n",
    "\n",
    "fallback_days = (df['date'] - pd.to_datetime('2011-01-29')).dt.days\n",
    "df['days_since_last_sale'] = df.groupby('id')['sold'].transform(days_since_last_sale)\n",
    "df['days_since_last_sale'] = df['days_since_last_sale'].fillna(fallback_days)\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:30:55.704045Z",
     "iopub.status.busy": "2025-05-02T00:30:55.703578Z",
     "iopub.status.idle": "2025-05-02T00:31:44.606592Z",
     "shell.execute_reply": "2025-05-02T00:31:44.605546Z",
     "shell.execute_reply.started": "2025-05-02T00:30:55.704012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/242494185.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['dept_sales'] = df.groupby(['dept_id', 'd'])['sold'].transform('mean')\n",
      "/tmp/ipykernel_212/242494185.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['store_sales'] = df.groupby(['store_id', 'd'])['sold'].transform('mean')\n",
      "/tmp/ipykernel_212/242494185.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['state_sales'] = df.groupby(['state_id', 'd'])['sold'].transform('mean')\n",
      "/tmp/ipykernel_212/242494185.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['cat_sales'] = df.groupby(['cat_id', 'd'])['sold'].transform('mean')\n",
      "/tmp/ipykernel_212/242494185.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby(['store_id', 'dept_id'])['sold']\n",
      "/tmp/ipykernel_212/242494185.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby(['store_id', 'dept_id'])['rolling_mean_store_dept_7']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 66)\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical Aggregated Features\n",
    "\n",
    "# Aggregated average sales at dept level\n",
    "df['dept_sales'] = df.groupby(['dept_id', 'd'])['sold'].transform('mean')\n",
    "\n",
    "# Aggregated average sales at store level\n",
    "df['store_sales'] = df.groupby(['store_id', 'd'])['sold'].transform('mean')\n",
    "\n",
    "# Aggregated average sales at state level\n",
    "df['state_sales'] = df.groupby(['state_id', 'd'])['sold'].transform('mean')\n",
    "\n",
    "# Aggregated average sales at category level\n",
    "df['cat_sales'] = df.groupby(['cat_id', 'd'])['sold'].transform('mean')\n",
    "\n",
    "df['rolling_mean_store_dept_7'] = (\n",
    "    df.groupby(['store_id', 'dept_id'])['sold']\n",
    "      .transform(lambda x: x.shift(1).rolling(7).mean())\n",
    ")\n",
    "\n",
    "# Add a 7-day lag of that rolling mean\n",
    "df['rolling_mean_store_dept_7_lag_7'] = (\n",
    "    df.groupby(['store_id', 'dept_id'])['rolling_mean_store_dept_7']\n",
    "      .shift(7)\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:31:44.607986Z",
     "iopub.status.busy": "2025-05-02T00:31:44.607661Z",
     "iopub.status.idle": "2025-05-02T00:32:06.317958Z",
     "shell.execute_reply": "2025-05-02T00:32:06.316834Z",
     "shell.execute_reply.started": "2025-05-02T00:31:44.607955Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/1950850414.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['rolling_mean_7_lag_7'] = df.groupby('id')['rolling_mean_7'].shift(7)\n",
      "/tmp/ipykernel_212/1950850414.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['rolling_mean_14_lag_14'] = df.groupby('id')['rolling_mean_14'].shift(14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 69)\n"
     ]
    }
   ],
   "source": [
    "# Lag on Engineered Features\n",
    "\n",
    "df['rolling_mean_7_lag_7'] = df.groupby('id')['rolling_mean_7'].shift(7)\n",
    "df['rolling_mean_14_lag_14'] = df.groupby('id')['rolling_mean_14'].shift(14)\n",
    "df['rolling_mean_change'] = df['rolling_mean_7'] - df['rolling_mean_7_lag_7']\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:32:06.319327Z",
     "iopub.status.busy": "2025-05-02T00:32:06.319030Z",
     "iopub.status.idle": "2025-05-02T00:33:36.006535Z",
     "shell.execute_reply": "2025-05-02T00:33:36.005513Z",
     "shell.execute_reply.started": "2025-05-02T00:32:06.319301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59181090, 69)\n",
      "After memory reduction:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59181090 entries, 0 to 59181089\n",
      "Data columns (total 69 columns):\n",
      " #   Column                           Dtype         \n",
      "---  ------                           -----         \n",
      " 0   id                               category      \n",
      " 1   item_id                          category      \n",
      " 2   dept_id                          category      \n",
      " 3   cat_id                           category      \n",
      " 4   store_id                         category      \n",
      " 5   state_id                         category      \n",
      " 6   d                                category      \n",
      " 7   sold                             int16         \n",
      " 8   date                             datetime64[ns]\n",
      " 9   wm_yr_wk                         int16         \n",
      " 10  weekday                          category      \n",
      " 11  wday                             int8          \n",
      " 12  month                            int8          \n",
      " 13  year                             int16         \n",
      " 14  event_name_1                     category      \n",
      " 15  event_type_1                     category      \n",
      " 16  event_name_2                     category      \n",
      " 17  event_type_2                     category      \n",
      " 18  snap_CA                          int8          \n",
      " 19  snap_TX                          int8          \n",
      " 20  snap_WI                          int8          \n",
      " 21  sell_price                       float16       \n",
      " 22  weekofyear                       UInt32        \n",
      " 23  dayofmonth                       int8          \n",
      " 24  day_of_year                      int16         \n",
      " 25  weekend                          int8          \n",
      " 26  is_month_start                   int8          \n",
      " 27  is_month_end                     int8          \n",
      " 28  is_quarter_start                 int8          \n",
      " 29  is_quarter_end                   int8          \n",
      " 30  is_event                         int8          \n",
      " 31  days_since_event                 float16       \n",
      " 32  days_until_event                 float16       \n",
      " 33  price_max                        float16       \n",
      " 34  price_min                        float16       \n",
      " 35  price_std                        float16       \n",
      " 36  price_norm                       float16       \n",
      " 37  price_momentum                   float16       \n",
      " 38  price_change_from_last_month     float16       \n",
      " 39  discount_flag                    int8          \n",
      " 40  snap_active                      int8          \n",
      " 41  days_since_snap                  float16       \n",
      " 42  days_until_next_snap             float16       \n",
      " 43  sales_lag_1                      float16       \n",
      " 44  sales_lag_7                      float16       \n",
      " 45  sales_lag_14                     float16       \n",
      " 46  sales_lag_28                     float16       \n",
      " 47  rolling_mean_7                   float16       \n",
      " 48  rolling_std_7                    float16       \n",
      " 49  rolling_mean_14                  float16       \n",
      " 50  rolling_std_14                   float16       \n",
      " 51  expanding_mean                   float16       \n",
      " 52  rolling_min_7                    float16       \n",
      " 53  rolling_max_7                    float16       \n",
      " 54  snap_event                       int8          \n",
      " 55  price_event                      int8          \n",
      " 56  weekend_event                    int8          \n",
      " 57  cumulative_sales                 int32         \n",
      " 58  cumulative_mean_sales            float16       \n",
      " 59  days_since_last_sale             float16       \n",
      " 60  dept_sales                       float16       \n",
      " 61  store_sales                      float16       \n",
      " 62  state_sales                      float16       \n",
      " 63  cat_sales                        float16       \n",
      " 64  rolling_mean_store_dept_7        float16       \n",
      " 65  rolling_mean_store_dept_7_lag_7  float16       \n",
      " 66  rolling_mean_7_lag_7             float16       \n",
      " 67  rolling_mean_14_lag_14           float16       \n",
      " 68  rolling_mean_change              float16       \n",
      "dtypes: UInt32(1), category(12), datetime64[ns](1), float16(33), int16(4), int32(1), int8(17)\n",
      "memory usage: 6.8 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Downcast the data for easy and fast processing\n",
    "def downcast(df):\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "\n",
    "    for i, t in enumerate(types):\n",
    "        col = cols[i]\n",
    "\n",
    "        if 'int' in str(t):\n",
    "            if df[col].min() > np.iinfo(np.int8).min and df[col].max() < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif df[col].min() > np.iinfo(np.int16).min and df[col].max() < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif df[col].min() > np.iinfo(np.int32).min and df[col].max() < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "\n",
    "        elif 'float' in str(t):\n",
    "            if df[col].min() > np.finfo(np.float16).min and df[col].max() < np.finfo(np.float16).max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif df[col].min() > np.finfo(np.float32).min and df[col].max() < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        elif t == object:\n",
    "            if col == 'date':\n",
    "                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = downcast(df)\n",
    "\n",
    "# Convert date column back to datetime\n",
    "df['date'] = df['date'].astype(str)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.to_feather('/kaggle/working/df.feather')\n",
    "\n",
    "print(df.shape)\n",
    "print('After memory reduction:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:35:40.126231Z",
     "iopub.status.busy": "2025-05-02T00:35:40.125512Z",
     "iopub.status.idle": "2025-05-02T00:35:57.481059Z",
     "shell.execute_reply": "2025-05-02T00:35:57.479282Z",
     "shell.execute_reply.started": "2025-05-02T00:35:40.126194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59181090, 69)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(\"/kaggle/working/df.feather\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:36:00.048770Z",
     "iopub.status.busy": "2025-05-02T00:36:00.048310Z",
     "iopub.status.idle": "2025-05-02T00:36:30.171728Z",
     "shell.execute_reply": "2025-05-02T00:36:30.170686Z",
     "shell.execute_reply.started": "2025-05-02T00:36:00.048734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58327370, 69)\n"
     ]
    }
   ],
   "source": [
    "# Dropping data for first 28 days to take care for NA values\n",
    "df = df[df['date'] > '2011-02-25'].reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:36:30.173864Z",
     "iopub.status.busy": "2025-05-02T00:36:30.173527Z",
     "iopub.status.idle": "2025-05-02T00:36:31.041666Z",
     "shell.execute_reply": "2025-05-02T00:36:31.040734Z",
     "shell.execute_reply.started": "2025-05-02T00:36:30.173837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_262/2616146203.py:5: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "cols_to_replace = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "\n",
    "for col in cols_to_replace:\n",
    "    if col in df.columns:\n",
    "        if pd.api.types.is_categorical_dtype(df[col]):\n",
    "            # Add \"no\" to category list if it's not already present\n",
    "            if \"no\" not in df[col].cat.categories:\n",
    "                df[col] = df[col].cat.add_categories(\"no\")\n",
    "        # Now fill the NaNs\n",
    "        df[col] = df[col].fillna(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:36:31.042906Z",
     "iopub.status.busy": "2025-05-02T00:36:31.042611Z",
     "iopub.status.idle": "2025-05-02T00:36:33.900475Z",
     "shell.execute_reply": "2025-05-02T00:36:33.899763Z",
     "shell.execute_reply.started": "2025-05-02T00:36:31.042885Z"
    }
   },
   "outputs": [],
   "source": [
    "price_na_cols = ['sell_price', 'price_norm', 'price_momentum']\n",
    "\n",
    "for col in price_na_cols:\n",
    "    df[f'{col}_is_missing'] = df[col].isna().astype(int)\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:36:33.902443Z",
     "iopub.status.busy": "2025-05-02T00:36:33.902074Z",
     "iopub.status.idle": "2025-05-02T00:36:35.781165Z",
     "shell.execute_reply": "2025-05-02T00:36:35.780475Z",
     "shell.execute_reply.started": "2025-05-02T00:36:33.902419Z"
    }
   },
   "outputs": [],
   "source": [
    "forward_looking_cols = ['days_until_event', 'days_until_next_snap']\n",
    "\n",
    "for col in forward_looking_cols:\n",
    "    df[f'{col}_is_missing'] = df[col].isna().astype(int)\n",
    "    df[col] = df[col].fillna(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T00:36:35.782175Z",
     "iopub.status.busy": "2025-05-02T00:36:35.781923Z",
     "iopub.status.idle": "2025-05-02T00:36:47.122799Z",
     "shell.execute_reply": "2025-05-02T00:36:47.121782Z",
     "shell.execute_reply.started": "2025-05-02T00:36:35.782147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58327370, 74)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.to_feather('/kaggle/working/df.feather')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1236839,
     "sourceId": 18599,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
