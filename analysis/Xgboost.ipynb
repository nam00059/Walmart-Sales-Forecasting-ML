{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:19.853838Z",
     "iopub.status.busy": "2025-05-03T18:19:19.853468Z",
     "iopub.status.idle": "2025-05-03T18:19:22.263037Z",
     "shell.execute_reply": "2025-05-03T18:19:22.262007Z",
     "shell.execute_reply.started": "2025-05-03T18:19:19.853809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:22.265287Z",
     "iopub.status.busy": "2025-05-03T18:19:22.264700Z",
     "iopub.status.idle": "2025-05-03T18:19:38.274600Z",
     "shell.execute_reply": "2025-05-03T18:19:38.273038Z",
     "shell.execute_reply.started": "2025-05-03T18:19:22.265248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the data \n",
    "df = pd.read_feather(\"/kaggle/input/df-feather/df.feather\")\n",
    "df['store_id'] = df['store_id'].astype(str)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-03T18:19:38.275417Z",
     "iopub.status.idle": "2025-05-03T18:19:38.275853Z",
     "shell.execute_reply": "2025-05-03T18:19:38.275640Z",
     "shell.execute_reply.started": "2025-05-03T18:19:38.275623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# separate df.feather by store\n",
    "for store_id in df['store_id'].unique():\n",
    "    df_store = df[df['store_id'] == store_id].reset_index(drop=True)\n",
    "    df_store.to_feather(f\"store_{store_id}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:41.958067Z",
     "iopub.status.busy": "2025-05-03T18:19:41.957634Z",
     "iopub.status.idle": "2025-05-03T18:19:41.963855Z",
     "shell.execute_reply": "2025-05-03T18:19:41.962750Z",
     "shell.execute_reply.started": "2025-05-03T18:19:41.958038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== PARAMETERS =====\n",
    "FORECAST_DAYS = 28\n",
    "TARGET_COL = 'sold'\n",
    "EXCLUDED_COLS = ['id', 'd', 'sold', 'date']\n",
    "EVAL_DAYS = [f'd_{i}' for i in range(1942, 1970)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:43.022583Z",
     "iopub.status.busy": "2025-05-03T18:19:43.022244Z",
     "iopub.status.idle": "2025-05-03T18:19:43.265119Z",
     "shell.execute_reply": "2025-05-03T18:19:43.264212Z",
     "shell.execute_reply.started": "2025-05-03T18:19:43.022554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== LOAD STATIC FILES =====\n",
    "calendar = pd.read_csv(\"/kaggle/input/calendar-csv/calendar.csv\")\n",
    "sample_submission = pd.read_csv(\"/kaggle/input/sample-submission-csv/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:44.324827Z",
     "iopub.status.busy": "2025-05-03T18:19:44.324414Z",
     "iopub.status.idle": "2025-05-03T18:19:44.346404Z",
     "shell.execute_reply": "2025-05-03T18:19:44.345044Z",
     "shell.execute_reply.started": "2025-05-03T18:19:44.324796Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== EVALUATION ROW BUILDER =====\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def generate_evaluation_rows(df_store, calendar, sample_submission):\n",
    "    start_time = time.time()\n",
    "    print(\"🔧 [Start] Generating evaluation rows...\")\n",
    "\n",
    "    sub_eval = sample_submission[sample_submission['id'].str.endswith('_evaluation')].copy()\n",
    "    sub_eval['item_id'] = sub_eval['id'].apply(lambda x: \"_\".join(x.split(\"_\")[:3]))\n",
    "    sub_eval['store_id'] = sub_eval['id'].apply(lambda x: \"_\".join(x.split(\"_\")[3:-1]))\n",
    "\n",
    "    store_id = df_store['store_id'].iloc[0]\n",
    "    sub_eval = sub_eval[sub_eval['store_id'] == store_id]\n",
    "\n",
    "    calendar_eval = calendar[calendar['d'].isin(EVAL_DAYS)][['d', 'wm_yr_wk', 'event_name_1', 'event_type_1',\n",
    "                                                             'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'date']]\n",
    "\n",
    "    eval_rows = []\n",
    "    for _, row in tqdm(sub_eval.iterrows(), total=len(sub_eval), desc=f\"🛠 Building eval rows for {store_id}\"):\n",
    "        base = df_store[(df_store['item_id'] == row['item_id']) & (df_store['store_id'] == row['store_id'])]\n",
    "        if base.empty:\n",
    "            continue\n",
    "        base = base.sort_values('d').iloc[-1:].copy()\n",
    "        for d in EVAL_DAYS:\n",
    "            temp = base.copy()\n",
    "            temp['d'] = d\n",
    "            temp['id'] = row['id']\n",
    "            eval_rows.append(temp)\n",
    "\n",
    "    df_eval = pd.concat(eval_rows, ignore_index=True)\n",
    "    df_eval = df_eval.merge(calendar_eval, on='d', how='left')\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"✅ [Done] Eval rows for {store_id} built in {elapsed:.2f} seconds.\")\n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T18:19:46.531606Z",
     "iopub.status.busy": "2025-05-03T18:19:46.531210Z",
     "iopub.status.idle": "2025-05-03T18:19:46.536702Z",
     "shell.execute_reply": "2025-05-03T18:19:46.535595Z",
     "shell.execute_reply.started": "2025-05-03T18:19:46.531578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== MERGE PREDICTED OUTPUT =====\n",
    "def merge_preds(pred_list):\n",
    "    df_merge = pred_list[0]\n",
    "    for t in range(1, FORECAST_DAYS):\n",
    "        df_merge = df_merge.merge(pred_list[t], on='id')\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T03:39:18.309884Z",
     "iopub.status.busy": "2025-05-03T03:39:18.309559Z",
     "iopub.status.idle": "2025-05-03T08:37:22.339020Z",
     "shell.execute_reply": "2025-05-03T08:37:22.336997Z",
     "shell.execute_reply.started": "2025-05-03T03:39:18.309864Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "🛒 Starting store: WI\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for WI_3: 100%|██████████| 3049/3049 [15:35<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for WI_3 built in 973.97 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store WI...\n",
      "✅ Done: val_WI.csv & eval_WI.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: CA\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for CA_2: 100%|██████████| 3049/3049 [15:28<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for CA_2 built in 966.74 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store CA...\n",
      "✅ Done: val_CA.csv & eval_CA.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: WI\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for WI_2: 100%|██████████| 3049/3049 [15:30<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for WI_2 built in 968.94 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store WI...\n",
      "✅ Done: val_WI.csv & eval_WI.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: CA\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for CA_1: 100%|██████████| 3049/3049 [15:30<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for CA_1 built in 968.94 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store CA...\n",
      "✅ Done: val_CA.csv & eval_CA.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: CA\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for CA_3: 100%|██████████| 3049/3049 [15:31<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for CA_3 built in 974.85 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store CA...\n",
      "✅ Done: val_CA.csv & eval_CA.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: TX\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for TX_3: 100%|██████████| 3049/3049 [15:28<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for TX_3 built in 967.74 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store TX...\n",
      "✅ Done: val_TX.csv & eval_TX.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: CA\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for CA_4: 100%|██████████| 3049/3049 [15:28<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for CA_4 built in 967.06 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store CA...\n",
      "✅ Done: val_CA.csv & eval_CA.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: TX\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for TX_2: 100%|██████████| 3049/3049 [15:28<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for TX_2 built in 967.02 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store TX...\n",
      "✅ Done: val_TX.csv & eval_TX.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: TX\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for TX_1: 100%|██████████| 3049/3049 [15:22<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for TX_1 built in 955.93 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store TX...\n",
      "✅ Done: val_TX.csv & eval_TX.csv\n",
      "\n",
      "==========================\n",
      "🛒 Starting store: WI\n",
      "==========================\n",
      "🔧 Generating evaluation rows...\n",
      "🔧 [Start] Generating evaluation rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🛠 Building eval rows for WI_1: 100%|██████████| 3049/3049 [15:35<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [Done] Eval rows for WI_1 built in 972.87 seconds.\n",
      "🧼 Encoding categorical + scaling numeric features...\n",
      "📅 Forecasting F01 (val: d_1914, eval: d_1942)\n",
      "📅 Forecasting F02 (val: d_1915, eval: d_1943)\n",
      "📅 Forecasting F03 (val: d_1916, eval: d_1944)\n",
      "📅 Forecasting F04 (val: d_1917, eval: d_1945)\n",
      "📅 Forecasting F05 (val: d_1918, eval: d_1946)\n",
      "📅 Forecasting F06 (val: d_1919, eval: d_1947)\n",
      "📅 Forecasting F07 (val: d_1920, eval: d_1948)\n",
      "📅 Forecasting F08 (val: d_1921, eval: d_1949)\n",
      "📅 Forecasting F09 (val: d_1922, eval: d_1950)\n",
      "📅 Forecasting F10 (val: d_1923, eval: d_1951)\n",
      "📅 Forecasting F11 (val: d_1924, eval: d_1952)\n",
      "📅 Forecasting F12 (val: d_1925, eval: d_1953)\n",
      "📅 Forecasting F13 (val: d_1926, eval: d_1954)\n",
      "📅 Forecasting F14 (val: d_1927, eval: d_1955)\n",
      "📅 Forecasting F15 (val: d_1928, eval: d_1956)\n",
      "📅 Forecasting F16 (val: d_1929, eval: d_1957)\n",
      "📅 Forecasting F17 (val: d_1930, eval: d_1958)\n",
      "📅 Forecasting F18 (val: d_1931, eval: d_1959)\n",
      "📅 Forecasting F19 (val: d_1932, eval: d_1960)\n",
      "📅 Forecasting F20 (val: d_1933, eval: d_1961)\n",
      "📅 Forecasting F21 (val: d_1934, eval: d_1962)\n",
      "📅 Forecasting F22 (val: d_1935, eval: d_1963)\n",
      "📅 Forecasting F23 (val: d_1936, eval: d_1964)\n",
      "📅 Forecasting F24 (val: d_1937, eval: d_1965)\n",
      "📅 Forecasting F25 (val: d_1938, eval: d_1966)\n",
      "📅 Forecasting F26 (val: d_1939, eval: d_1967)\n",
      "📅 Forecasting F27 (val: d_1940, eval: d_1968)\n",
      "📅 Forecasting F28 (val: d_1941, eval: d_1969)\n",
      "💾 Saving outputs for store WI...\n",
      "✅ Done: val_WI.csv & eval_WI.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== MAIN PIPELINE LOOP =====\n",
    "store_files = [f for f in os.listdir() if f.startswith(\"store_\") and f.endswith(\".feather\")]\n",
    "\n",
    "for file in store_files:\n",
    "    store_id = file.replace(\"store_\", \"\").replace(\".feather\", \"\")\n",
    "    print(f\"\\n==========================\")\n",
    "    print(f\"🛒 Starting store: {store_id}\")\n",
    "    print(\"==========================\")\n",
    "\n",
    "    df_store = pd.read_feather(file)\n",
    "    df_store['d'] = df_store['d'].astype(str)\n",
    "\n",
    "    print(\"🔧 Generating evaluation rows...\")\n",
    "    df_eval = generate_evaluation_rows(df_store, calendar, sample_submission)\n",
    "    df_store = pd.concat([df_store, df_eval], ignore_index=True)\n",
    "\n",
    "    print(\"🧼 Encoding categorical + scaling numeric features...\")\n",
    "    cat_cols = [col for col in df_store.select_dtypes(include='category') if col not in EXCLUDED_COLS]\n",
    "    num_cols = [col for col in df_store.select_dtypes(include=['float', 'int']) if col not in EXCLUDED_COLS]\n",
    "    encoders = {col: LabelEncoder().fit(df_store[col]) for col in cat_cols}\n",
    "    for col in cat_cols:\n",
    "        df_store[col] = encoders[col].transform(df_store[col])\n",
    "    scaler = MinMaxScaler()\n",
    "    df_store[num_cols] = scaler.fit_transform(df_store[num_cols])\n",
    "    features = cat_cols + num_cols\n",
    "\n",
    "    val_preds, eval_preds = [], []\n",
    "\n",
    "    for t in range(1, FORECAST_DAYS + 1):\n",
    "        d_val = f'd_{1913 + t}'\n",
    "        d_eval = f'd_{1941 + t}'\n",
    "        print(f\"📅 Forecasting F{t:02d} (val: {d_val}, eval: {d_eval})\")\n",
    "\n",
    "        # Validation\n",
    "        train_val = df_store[df_store['d'] < d_val]\n",
    "        test_val = df_store[df_store['d'] == d_val]\n",
    "        if test_val.empty:\n",
    "            print(\"  ⚠️ Skipped validation day (no data)\")\n",
    "            continue\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=6,\n",
    "                                 learning_rate=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                 tree_method='hist', verbosity=0)\n",
    "        model.fit(train_val[features], train_val[TARGET_COL])\n",
    "        y_pred_val = model.predict(test_val[features]).ravel()\n",
    "        id_val = test_val['id'].str.replace(\"_evaluation\", \"_validation\").values.ravel()\n",
    "        val_preds.append(pd.DataFrame({'id': id_val, f'F{t}': y_pred_val}))\n",
    "\n",
    "        # Evaluation\n",
    "        train_eval = df_store[df_store['d'] < d_eval]\n",
    "        test_eval = df_store[df_store['d'] == d_eval]\n",
    "        if test_eval.empty:\n",
    "            print(\"  ⚠️ Skipped evaluation day (no data)\")\n",
    "            continue\n",
    "        model.fit(train_eval[features], train_eval[TARGET_COL])\n",
    "        y_pred_eval = model.predict(test_eval[features]).ravel()\n",
    "        id_eval = test_eval['id'].values.ravel()\n",
    "        eval_preds.append(pd.DataFrame({'id': id_eval, f'F{t}': y_pred_eval}))\n",
    "\n",
    "    # Save outputs\n",
    "    print(f\"💾 Saving outputs for store {store_id}...\")\n",
    "    submission_val = merge_preds(val_preds)\n",
    "    submission_eval = merge_preds(eval_preds)\n",
    "    submission_val.to_csv(f\"val_{store_id}.csv\", index=False)\n",
    "    submission_eval.to_csv(f\"eval_{store_id}.csv\", index=False)\n",
    "    print(f\"✅ Done: val_{store_id}.csv & eval_{store_id}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7307001,
     "sourceId": 11644561,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7314982,
     "sourceId": 11656286,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7314990,
     "sourceId": 11656300,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
